{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing,model_selection as cross_validation, neighbors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Breast Cancer Data \n",
    "#Read the breast cancer data from the data file\n",
    "df = pd.read_csv('C:\\\\Users\\\\GQPF6681\\\\Desktop\\\\breast-cancer-wisconsin.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean bad data\n",
    "df.replace('?',-99999, inplace=True) # better strategy is to replace the question marks with the mode of the column \n",
    "                                     # here , we are replacing ? with -99999 so that it lies in outlier \n",
    "#Drop unwanted columns like id\n",
    "df.drop(['id'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class needs to be predicted. Remove this from the data frame\n",
    "X = np.array(df.drop(['class'], 1))\n",
    "#Class is what needs to be predicted\n",
    "y = np.array(df['class'])\n",
    "#Use 20% data for testing and 80% data for training\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "#Nearest neighbor classifier from skikit learn\n",
    "clf = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9785714285714285\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "#Pass a new measurement and predict\n",
    "example_measures = np.array([4,2,1,1,1,2,3,2,1]).reshape(1, -1)\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived                                             name     sex  \\\n",
      "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
      "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
      "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
      "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
      "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
      "\n",
      "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
      "0  29.0000    0.0    0.0   24160  211.3375       B5        S    2    NaN   \n",
      "1   0.9167    1.0    2.0  113781  151.5500  C22 C26        S   11    NaN   \n",
      "2   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "3  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN  135.0   \n",
      "4  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n"
     ]
    }
   ],
   "source": [
    "# using Titanic Data \n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\GQPF6681\\\\Desktop\\\\titanic_data.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex      age  sibsp  parch      fare embarked\n",
       "0     1.0       1.0  female  29.0000    0.0    0.0  211.3375        S\n",
       "1     1.0       1.0    male   0.9167    1.0    2.0  151.5500        S\n",
       "2     1.0       0.0  female   2.0000    1.0    2.0  151.5500        S\n",
       "3     1.0       0.0    male  30.0000    1.0    2.0  151.5500        S\n",
       "4     1.0       0.0  female  25.0000    1.0    2.0  151.5500        S\n",
       "5     1.0       1.0    male  48.0000    0.0    0.0   26.5500        S\n",
       "6     1.0       1.0  female  63.0000    1.0    0.0   77.9583        S\n",
       "7     1.0       0.0    male  39.0000    0.0    0.0    0.0000        S\n",
       "8     1.0       1.0  female  53.0000    2.0    0.0   51.4792        S\n",
       "9     1.0       0.0    male  71.0000    0.0    0.0   49.5042        C"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df.drop(['name','ticket','cabin','boat', 'body', 'home.dest'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex      age  sibsp  parch      fare embarked\n",
       "0     1.0       1.0  female  29.0000    0.0    0.0  211.3375        S\n",
       "1     1.0       1.0    male   0.9167    1.0    2.0  151.5500        S\n",
       "2     1.0       0.0  female   2.0000    1.0    2.0  151.5500        S\n",
       "3     1.0       0.0    male  30.0000    1.0    2.0  151.5500        S\n",
       "4     1.0       0.0  female  25.0000    1.0    2.0  151.5500        S\n",
       "5     1.0       1.0    male  48.0000    0.0    0.0   26.5500        S\n",
       "6     1.0       1.0  female  63.0000    1.0    0.0   77.9583        S\n",
       "7     1.0       0.0    male  39.0000    0.0    0.0    0.0000        S\n",
       "8     1.0       1.0  female  53.0000    2.0    0.0   51.4792        S\n",
       "9     1.0       0.0    male  71.0000    0.0    0.0   49.5042        C"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch      fare embarked\n",
       "0     1.0       1.0    0  29.0000    0.0    0.0  211.3375        S\n",
       "1     1.0       1.0    1   0.9167    1.0    2.0  151.5500        S\n",
       "2     1.0       0.0    0   2.0000    1.0    2.0  151.5500        S\n",
       "3     1.0       0.0    1  30.0000    1.0    2.0  151.5500        S\n",
       "4     1.0       0.0    0  25.0000    1.0    2.0  151.5500        S\n",
       "5     1.0       1.0    1  48.0000    0.0    0.0   26.5500        S\n",
       "6     1.0       1.0    0  63.0000    1.0    0.0   77.9583        S\n",
       "7     1.0       0.0    1  39.0000    0.0    0.0    0.0000        S\n",
       "8     1.0       1.0    0  53.0000    2.0    0.0   51.4792        S\n",
       "9     1.0       0.0    1  71.0000    0.0    0.0   49.5042        C"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch      fare  embarked\n",
       "0     1.0       1.0    0  29.0000    0.0    0.0  211.3375         0\n",
       "1     1.0       1.0    1   0.9167    1.0    2.0  151.5500         0\n",
       "2     1.0       0.0    0   2.0000    1.0    2.0  151.5500         0\n",
       "3     1.0       0.0    1  30.0000    1.0    2.0  151.5500         0\n",
       "4     1.0       0.0    0  25.0000    1.0    2.0  151.5500         0\n",
       "5     1.0       1.0    1  48.0000    0.0    0.0   26.5500         0\n",
       "6     1.0       1.0    0  63.0000    1.0    0.0   77.9583         0\n",
       "7     1.0       0.0    1  39.0000    0.0    0.0    0.0000         0\n",
       "8     1.0       1.0    0  53.0000    2.0    0.0   51.4792         0\n",
       "9     1.0       0.0    1  71.0000    0.0    0.0   49.5042         1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class needs to be predicted. Remove this from the data frame\n",
    "X = np.array(df.drop(['survived'], 1))\n",
    "#Class is what needs to be predicted\n",
    "y = np.array(df['survived'])\n",
    "#Use 20% data for testing and 80% data for training\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "#Nearest neighbor classifier from skikit learn\n",
    "clf = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6603053435114504\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM ( Support Vector machine)\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, model_selection as cross_validation, neighbors, svm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data, clean data and drop unwanted features\n",
    "df = pd.read_csv('C:\\\\Users\\\\GQPF6681\\\\Desktop\\\\breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "\n",
    "#Drop prediction class from data set, Add to y\n",
    "X = np.array(df.drop(['class'], 1))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "#80-20 for train:test\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "\n",
    "#Run SVM and calculate confidence\n",
    "clf.fit(X_train, y_train)\n",
    "confidence = clf.score(X_test, y_test)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "example_measures = np.array([[4,2,1,1,1,2,3,2,1]])\n",
    "example_measures = example_measures.reshape(len(example_measures), -1)\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived                                             name     sex  \\\n",
      "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
      "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
      "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
      "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
      "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
      "\n",
      "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
      "0  29.0000    0.0    0.0   24160  211.3375       B5        S    2    NaN   \n",
      "1   0.9167    1.0    2.0  113781  151.5500  C22 C26        S   11    NaN   \n",
      "2   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "3  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN  135.0   \n",
      "4  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n"
     ]
    }
   ],
   "source": [
    "# using Titanic Data \n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\GQPF6681\\\\Desktop\\\\titanic_data.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch      fare  embarked\n",
       "0     1.0       1.0    0  29.0000    0.0    0.0  211.3375         0\n",
       "1     1.0       1.0    1   0.9167    1.0    2.0  151.5500         0\n",
       "2     1.0       0.0    0   2.0000    1.0    2.0  151.5500         0\n",
       "3     1.0       0.0    1  30.0000    1.0    2.0  151.5500         0\n",
       "4     1.0       0.0    0  25.0000    1.0    2.0  151.5500         0\n",
       "5     1.0       1.0    1  48.0000    0.0    0.0   26.5500         0\n",
       "6     1.0       1.0    0  63.0000    1.0    0.0   77.9583         0\n",
       "7     1.0       0.0    1  39.0000    0.0    0.0    0.0000         0\n",
       "8     1.0       1.0    0  53.0000    2.0    0.0   51.4792         0\n",
       "9     1.0       0.0    1  71.0000    0.0    0.0   49.5042         1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['name','ticket','cabin','boat', 'body', 'home.dest'], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "df['sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "df['embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class needs to be predicted. Remove this from the data frame\n",
    "X = np.array(df.drop(['survived'], 1))\n",
    "#Class is what needs to be predicted\n",
    "y = np.array(df['survived'])\n",
    "#Use 20% data for testing and 80% data for training\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7099236641221374\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "#Run SVM and calculate confidence\n",
    "clf.fit(X_train, y_train)\n",
    "confidence = clf.score(X_test, y_test)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "example_measures = np.array([[1.0,1.0,30.0000,1.0,2.0,50.0000,1]])\n",
    "example_measures = example_measures.reshape(len(example_measures), -1)\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized a step.\n",
      "Optimized a step.\n",
      "Optimized a step.\n",
      "[5 1] : 1.0479999999990506\n",
      "[ 6 -1] : 1.7439999999985962\n",
      "[7 3] : 1.0479999999990506\n",
      "[1 7] : 1.271999999999435\n",
      "[2 8] : 1.271999999999435\n",
      "[3 8] : 1.0399999999995864\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# svm from scratch file \n",
    "# it shows the 2 planes drawn on the periphery of 2 classes and support vectoes and how a best plane separates the 2 classes optimally \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use('ggplot')\n",
    "\n",
    "class Support_Vector_Machine:\n",
    "    def __init__(self, visualization=True):\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "    # train\n",
    "    def fit(self, data):\n",
    "        self.data = data\n",
    "        # { ||w||: [w,b] }\n",
    "        opt_dict = {}\n",
    "\n",
    "        transforms = [[1,1],\n",
    "                      [-1,1],\n",
    "                      [-1,-1],\n",
    "                      [1,-1]]\n",
    "\n",
    "        all_data = []\n",
    "        for yi in self.data:\n",
    "            for featureset in self.data[yi]:\n",
    "                for feature in featureset:\n",
    "                    all_data.append(feature)\n",
    "\n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None\n",
    "\n",
    "        # support vectors yi(xi.w+b) = 1\n",
    "\n",
    "\n",
    "        step_sizes = [self.max_feature_value * 0.1,\n",
    "                      self.max_feature_value * 0.01,\n",
    "                      # point of expense:\n",
    "                      self.max_feature_value * 0.001,\n",
    "                      ]\n",
    "\n",
    "\n",
    "\n",
    "        # extremely expensive\n",
    "        b_range_multiple = 2\n",
    "        # we dont need to take as small of steps\n",
    "        # with b as we do w\n",
    "        b_multiple = 5\n",
    "        latest_optimum = self.max_feature_value*10\n",
    "\n",
    "        for step in step_sizes:\n",
    "            w = np.array([latest_optimum,latest_optimum])\n",
    "            # we can do this because convex\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        found_option = True\n",
    "                        # weakest link in the SVM fundamentally\n",
    "                        # SMO attempts to fix this a bit\n",
    "                        # yi(xi.w+b) >= 1\n",
    "                        #\n",
    "                        # #### add a break here later..\n",
    "                        for i in self.data:\n",
    "                            for xi in self.data[i]:\n",
    "                                yi=i\n",
    "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
    "                                    found_option = False\n",
    "                                    #print(xi,':',yi*(np.dot(w_t,xi)+b))\n",
    "\n",
    "                        if found_option:\n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
    "\n",
    "                if w[0] < 0:\n",
    "                    optimized = True\n",
    "                    print('Optimized a step.')\n",
    "                else:\n",
    "                    w = w - step\n",
    "\n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            #||w|| : [w,b]\n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "            self.w = opt_choice[0]\n",
    "            self.b = opt_choice[1]\n",
    "            latest_optimum = opt_choice[0][0]+step*2\n",
    "\n",
    "        for i in self.data:\n",
    "            for xi in self.data[i]:\n",
    "                yi=i\n",
    "                print(xi,':',yi*(np.dot(self.w,xi)+self.b))\n",
    "\n",
    "    def predict(self,features):\n",
    "        # sign( x.w+b )\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        if classification !=0 and self.visualization:\n",
    "            self.ax.scatter(features[0], features[1], s=200, marker='*', c=self.colors[classification])\n",
    "        return classification\n",
    "\n",
    "    def visualize(self):\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "\n",
    "        # hyperplane = x.w+b\n",
    "        # v = x.w+b\n",
    "        # psv = 1\n",
    "        # nsv = -1\n",
    "        # dec = 0\n",
    "        def hyperplane(x,w,b,v):\n",
    "            return (-w[0]*x-b+v) / w[1]\n",
    "\n",
    "        datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "\n",
    "        # (w.x+b) = 1\n",
    "        # positive support vector hyperplane\n",
    "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
    "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2], 'k')\n",
    "\n",
    "        # (w.x+b) = -1\n",
    "        # negative support vector hyperplane\n",
    "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
    "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2], 'k')\n",
    "\n",
    "        # (w.x+b) = 0\n",
    "        # positive support vector hyperplane\n",
    "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
    "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2], 'y--')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "data_dict = {-1:np.array([[1,7],\n",
    "                          [2,8],\n",
    "                          [3,8],]),\n",
    "\n",
    "             1:np.array([[5,1],\n",
    "                         [6,-1],\n",
    "                         [7,3],])}\n",
    "\n",
    "svm = Support_Vector_Machine()\n",
    "svm.fit(data=data_dict)\n",
    "\n",
    "predict_us = [[0,10],\n",
    "              [1,3],\n",
    "              [3,4],\n",
    "              [3,5],\n",
    "              [5,5],\n",
    "              [5,6],\n",
    "              [6,-5],\n",
    "              [5,8]]\n",
    "\n",
    "for p in predict_us:\n",
    "    svm.predict(p)\n",
    "\n",
    "svm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes \n",
    "\n",
    "#Import Library of Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "#assigning predictor and target variables\n",
    "x= np.array([[-3,7],[1,5], [1,2], [-2,0], [2,3], [-4,0], [-1,1], [1,1], [-2,2], [2,7], [-4,1], [-2,7]])\n",
    "y = np.array([3, 3, 3, 3, 4, 3, 3, 4, 3, 4, 4, 4])\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(x, y)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict([[1,2],[3,4]])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using breast data \n",
    "df = pd.read_csv('C:\\\\Users\\\\GQPF6681\\\\Desktop\\\\breast-cancer-wisconsin.data')\n",
    "#Clean bad data\n",
    "df.replace('?',-99999, inplace=True) # better strategy is to replace the question marks with the mode of the column \n",
    "                                     # here , we are replacing ? with -99999 so that it lies in outlier \n",
    "#Drop unwanted columns like id\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "#Class needs to be predicted. Remove this from the data frame\n",
    "X = np.array(df.drop(['class'], 1))\n",
    "#Class is what needs to be predicted\n",
    "y = np.array(df['class'])\n",
    "#Use 20% data for testing and 80% data for training\n",
    "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,7) (9,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-cfe9680d70d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30.0000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50.0000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gqpf6681\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \"\"\"\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gqpf6681\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0mjointi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_prior_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mn_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigma_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) /\n\u001b[0m\u001b[0;32m    434\u001b[0m                                  (self.sigma_[i, :]), 1)\n\u001b[0;32m    435\u001b[0m             \u001b[0mjoint_log_likelihood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjointi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_ij\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,7) (9,) "
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X, y)\n",
    "predicted = model.predict([[1.0,1.0,30.0000,1.0,2.0,50.0000,1]])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 1.000\n",
      "Accuracy on the test subset: 0.937\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree \n",
    "\n",
    "#using breast cancer data \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy on the training subset: {:.3f}'.format(tree.score(X_train, y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using titanic data \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch      fare  embarked\n",
       "0     1.0       1.0    0  29.0000    0.0    0.0  211.3375         0\n",
       "1     1.0       1.0    1   0.9167    1.0    2.0  151.5500         0\n",
       "2     1.0       0.0    0   2.0000    1.0    2.0  151.5500         0\n",
       "3     1.0       0.0    1  30.0000    1.0    2.0  151.5500         0\n",
       "4     1.0       0.0    0  25.0000    1.0    2.0  151.5500         0\n",
       "5     1.0       1.0    1  48.0000    0.0    0.0   26.5500         0\n",
       "6     1.0       1.0    0  63.0000    1.0    0.0   77.9583         0\n",
       "7     1.0       0.0    1  39.0000    0.0    0.0    0.0000         0\n",
       "8     1.0       1.0    0  53.0000    2.0    0.0   51.4792         0\n",
       "9     1.0       0.0    1  71.0000    0.0    0.0   49.5042         1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\GQPF6681\\\\Desktop\\\\titanic_data.csv')\n",
    "df = df.drop(['name','ticket','cabin','boat', 'body', 'home.dest'], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "df['sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "df['embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 0.969\n",
      "Accuracy on the test subset: 0.779\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df.drop(['survived'], 1))\n",
    "#Class is what needs to be predicted\n",
    "y = np.array(df['survived'])\n",
    "#Use 20% data for testing and 80% data for training\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy on the training subset: {:.3f}'.format(tree.score(X_train, y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is diameter >= 3?\n",
      "--> True:\n",
      "  Is color == Yellow?\n",
      "  --> True:\n",
      "    Predict {'Lemon': 1, 'Apple': 1}\n",
      "  --> False:\n",
      "    Predict {'Apple': 1}\n",
      "--> False:\n",
      "  Predict {'Grape': 2}\n",
      "Actual: Apple. Predicted: {'Apple': '100%'}\n",
      "Actual: Apple. Predicted: {'Apple': '50%', 'Lemon': '50%'}\n",
      "Actual: Grape. Predicted: {'Grape': '100%'}\n",
      "Actual: Grape. Predicted: {'Grape': '100%'}\n",
      "Actual: Lemon. Predicted: {'Apple': '50%', 'Lemon': '50%'}\n"
     ]
    }
   ],
   "source": [
    "# decision trees from scratch\n",
    "\n",
    "# Toy dataset.\n",
    "# Format: each row is an example.\n",
    "# The last column is the label.\n",
    "# The first two columns are features.\n",
    "# Feel free to play with it by adding more features & examples.\n",
    "# Interesting note: I've written this so the 2nd and 5th examples\n",
    "# have the same features, but different labels - so we can see how the\n",
    "# tree handles this case.\n",
    "training_data = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]\n",
    "\n",
    "# Column labels.\n",
    "# These are used only to print the tree.\n",
    "header = [\"color\", \"diameter\", \"label\"]\n",
    "\n",
    "\n",
    "def unique_vals(rows, col):\n",
    "    \"\"\"Find the unique values for a column in a dataset.\"\"\"\n",
    "    return set([row[col] for row in rows])\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# unique_vals(training_data, 0)\n",
    "# unique_vals(training_data, 1)\n",
    "#######\n",
    "\n",
    "\n",
    "def class_counts(rows):\n",
    "    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
    "    counts = {}  # a dictionary of label -> count.\n",
    "    for row in rows:\n",
    "        # in our dataset format, the label is always the last column\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# class_counts(training_data)\n",
    "#######\n",
    "\n",
    "\n",
    "def is_numeric(value):\n",
    "    \"\"\"Test if a value is numeric.\"\"\"\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# is_numeric(7)\n",
    "# is_numeric(\"Red\")\n",
    "#######\n",
    "\n",
    "\n",
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset.\n",
    "    This class just records a 'column number' (e.g., 0 for Color) and a\n",
    "    'column value' (e.g., Green). The 'match' method is used to compare\n",
    "    the feature value in an example to the feature value stored in the\n",
    "    question. See the demo below.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def match(self, example):\n",
    "        # Compare the feature value in an example to the\n",
    "        # feature value in this question.\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header[self.column], condition, str(self.value))\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# Let's write a question for a numeric attribute\n",
    "# Question(1, 3)\n",
    "# How about one for a categorical attribute\n",
    "# q = Question(0, 'Green')\n",
    "# Let's pick an example from the training set...\n",
    "# example = training_data[0]\n",
    "# ... and see if it matches the question\n",
    "# q.match(example)\n",
    "#######\n",
    "\n",
    "\n",
    "def partition(rows, question):\n",
    "    \"\"\"Partitions a dataset.\n",
    "    For each row in the dataset, check if it matches the question. If\n",
    "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
    "    \"\"\"\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows\n",
    "\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# Let's partition the training data based on whether rows are Red.\n",
    "# true_rows, false_rows = partition(training_data, Question(0, 'Red'))\n",
    "# This will contain all the 'Red' rows.\n",
    "# true_rows\n",
    "# This will contain everything else.\n",
    "# false_rows\n",
    "#######\n",
    "\n",
    "def gini(rows):\n",
    "    \"\"\"Calculate the Gini Impurity for a list of rows.\n",
    "    There are a few different ways to do this, I thought this one was\n",
    "    the most concise. See:\n",
    "    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "    \"\"\"\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity\n",
    "\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# Let's look at some example to understand how Gini Impurity works.\n",
    "#\n",
    "# First, we'll look at a dataset with no mixing.\n",
    "# no_mixing = [['Apple'],\n",
    "#              ['Apple']]\n",
    "# this will return 0\n",
    "# gini(no_mixing)\n",
    "#\n",
    "# Now, we'll look at dataset with a 50:50 apples:oranges ratio\n",
    "# some_mixing = [['Apple'],\n",
    "#               ['Orange']]\n",
    "# this will return 0.5 - meaning, there's a 50% chance of misclassifying\n",
    "# a random example we draw from the dataset.\n",
    "# gini(some_mixing)\n",
    "#\n",
    "# Now, we'll look at a dataset with many different labels\n",
    "# lots_of_mixing = [['Apple'],\n",
    "#                  ['Orange'],\n",
    "#                  ['Grape'],\n",
    "#                  ['Grapefruit'],\n",
    "#                  ['Blueberry']]\n",
    "# This will return 0.8\n",
    "# gini(lots_of_mixing)\n",
    "#######\n",
    "\n",
    "def info_gain(left, right, current_uncertainty):\n",
    "    \"\"\"Information Gain.\n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "    \"\"\"\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - p * gini(left) - (1 - p) * gini(right)\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# Calculate the uncertainy of our training data.\n",
    "# current_uncertainty = gini(training_data)\n",
    "#\n",
    "# How much information do we gain by partioning on 'Green'?\n",
    "# true_rows, false_rows = partition(training_data, Question(0, 'Green'))\n",
    "# info_gain(true_rows, false_rows, current_uncertainty)\n",
    "#\n",
    "# What about if we partioned on 'Red' instead?\n",
    "# true_rows, false_rows = partition(training_data, Question(0,'Red'))\n",
    "# info_gain(true_rows, false_rows, current_uncertainty)\n",
    "#\n",
    "# It looks like we learned more using 'Red' (0.37), than 'Green' (0.14).\n",
    "# Why? Look at the different splits that result, and see which one\n",
    "# looks more 'unmixed' to you.\n",
    "# true_rows, false_rows = partition(training_data, Question(0,'Red'))\n",
    "#\n",
    "# Here, the true_rows contain only 'Grapes'.\n",
    "# true_rows\n",
    "#\n",
    "# And the false rows contain two types of fruit. Not too bad.\n",
    "# false_rows\n",
    "#\n",
    "# On the other hand, partitioning by Green doesn't help so much.\n",
    "# true_rows, false_rows = partition(training_data, Question(0,'Green'))\n",
    "#\n",
    "# We've isolated one apple in the true rows.\n",
    "# true_rows\n",
    "#\n",
    "# But, the false-rows are badly mixed up.\n",
    "# false_rows\n",
    "#######\n",
    "\n",
    "\n",
    "def find_best_split(rows):\n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "    and calculating the information gain.\"\"\"\n",
    "    best_gain = 0  # keep track of the best information gain\n",
    "    best_question = None  # keep train of the feature / value that produced it\n",
    "    current_uncertainty = gini(rows)\n",
    "    n_features = len(rows[0]) - 1  # number of columns\n",
    "\n",
    "    for col in range(n_features):  # for each feature\n",
    "\n",
    "        values = set([row[col] for row in rows])  # unique values in the column\n",
    "\n",
    "        for val in values:  # for each value\n",
    "\n",
    "            question = Question(col, val)\n",
    "\n",
    "            # try splitting the dataset\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "            # Skip this split if it doesn't divide the\n",
    "            # dataset.\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this split\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "\n",
    "            # You actually can use '>' instead of '>=' here\n",
    "            # but I wanted the tree to look a certain way for our\n",
    "            # toy dataset.\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# Find the best question to ask first for our toy dataset.\n",
    "# best_gain, best_question = find_best_split(training_data)\n",
    "# FYI: is color == Red is just as good. See the note in the code above\n",
    "# where I used '>='.\n",
    "#######\n",
    "\n",
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)\n",
    "\n",
    "\n",
    "class Decision_Node:\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "\n",
    "def build_tree(rows):\n",
    "    \"\"\"Builds the tree.\n",
    "    Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
    "    for the base case (no further information gain). 3) Prepare for\n",
    "    giant stack traces.\n",
    "    \"\"\"\n",
    "\n",
    "    # Try partitioing the dataset on each of the unique attribute,\n",
    "    # calculate the information gain,\n",
    "    # and return the question that produces the highest gain.\n",
    "    gain, question = find_best_split(rows)\n",
    "\n",
    "    # Base case: no further info gain\n",
    "    # Since we can ask no further questions,\n",
    "    # we'll return a leaf.\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "\n",
    "    # If we reach here, we have found a useful feature / value\n",
    "    # to partition on.\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "    # Recursively build the true branch.\n",
    "    true_branch = build_tree(true_rows)\n",
    "\n",
    "    # Recursively build the false branch.\n",
    "    false_branch = build_tree(false_rows)\n",
    "\n",
    "    # Return a Question node.\n",
    "    # This records the best feature / value to ask at this point,\n",
    "    # as well as the branches to follow\n",
    "    # dependingo on the answer.\n",
    "    return Decision_Node(question, true_branch, false_branch)\n",
    "\n",
    "\n",
    "def print_tree(node, spacing=\"\"):\n",
    "    \"\"\"World's most elegant tree printing function.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        print (spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "\n",
    "    # Print the question at this node\n",
    "    print (spacing + str(node.question))\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")\n",
    "\n",
    "\n",
    "def classify(row, node):\n",
    "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "\n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node,\n",
    "    # to the example we're considering.\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)\n",
    "\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# The tree predicts the 1st row of our\n",
    "# training data is an apple with confidence 1.\n",
    "# my_tree = build_tree(training_data)\n",
    "# classify(training_data[0], my_tree)\n",
    "#######\n",
    "\n",
    "def print_leaf(counts):\n",
    "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
    "    return probs\n",
    "\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# Printing that a bit nicer\n",
    "# print_leaf(classify(training_data[0], my_tree))\n",
    "#######\n",
    "\n",
    "#######\n",
    "# Demo:\n",
    "# On the second example, the confidence is lower\n",
    "# print_leaf(classify(training_data[1], my_tree))\n",
    "#######\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    my_tree = build_tree(training_data)\n",
    "\n",
    "    print_tree(my_tree)\n",
    "\n",
    "    # Evaluate\n",
    "    testing_data = [\n",
    "        ['Green', 3, 'Apple'],\n",
    "        ['Yellow', 4, 'Apple'],\n",
    "        ['Red', 2, 'Grape'],\n",
    "        ['Red', 1, 'Grape'],\n",
    "        ['Yellow', 3, 'Lemon'],\n",
    "    ]\n",
    "\n",
    "    for row in testing_data:\n",
    "        print (\"Actual: %s. Predicted: %s\" %\n",
    "               (row[-1], print_leaf(classify(row, my_tree))))\n",
    "\n",
    "# Next steps\n",
    "# - add support for missing (or unseen) attributes\n",
    "# - prune the tree to prevent overfitting\n",
    "# - add support for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision tree for regression \n",
    "# Import the necessary modules and libraries\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a random dataset\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "y[::5] += 3 * (0.5 - rng.rand(16))\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_2 = regr_2.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\",\n",
    "         label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
